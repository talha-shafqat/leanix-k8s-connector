package main

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
	"reflect"
	"strings"

	"github.com/leanix/leanix-k8s-connector/pkg/kubernetes"
	"github.com/leanix/leanix-k8s-connector/pkg/leanix"
	"github.com/leanix/leanix-k8s-connector/pkg/mapper"
	"github.com/leanix/leanix-k8s-connector/pkg/storage"
	"github.com/leanix/leanix-k8s-connector/pkg/version"
	flag "github.com/spf13/pflag"
	"github.com/spf13/viper"

	"github.com/op/go-logging"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/discovery"
	"k8s.io/client-go/dynamic"
	restclient "k8s.io/client-go/rest"
	"k8s.io/client-go/tools/clientcmd"
	"k8s.io/client-go/util/homedir"
)

const (
	clusterNameFlag         string = "clustername"
	storageBackendFlag      string = "storage-backend"
	azureAccountNameFlag    string = "azure-account-name"
	azureAccountKeyFlag     string = "azure-account-key"
	azureContainerFlag      string = "azure-container"
	localFilePathFlag       string = "local-file-path"
	verboseFlag             string = "verbose"
	connectorIDFlag         string = "connector-id"
	connectorVersionFlag    string = "connector-version"
	integrationAPIFlag      string = "integration-api-enabled"
	integrationAPIFqdnFlag  string = "integration-api-fqdn"
	integrationAPITokenFlag string = "integration-api-token"
	blacklistNamespacesFlag string = "blacklist-namespaces"
	lxWorkspaceFlag         string = "lx-workspace"
	localFlag               string = "local"
)

const lxVersion string = "1.0.0"

var log = logging.MustGetLogger("leanix-k8s-connector")

func main() {
	stdoutLogger, debugLogBuffer := initLogger()
	err := parseFlags()
	if err != nil {
		log.Fatal(err)
	}
	enableVerbose(stdoutLogger, viper.GetBool(verboseFlag))
	log.Info("----------Start----------")
	log.Infof("LeanIX Kubernetes connector build version: %s", version.VERSION)
	log.Infof("LeanIX integration version: %s", lxVersion)
	log.Infof("Target LeanIX workspace: %s", viper.GetString(lxWorkspaceFlag))
	log.Infof("Target Kubernetes cluster name: %s", viper.GetString(clusterNameFlag))

	var config *restclient.Config
	if viper.GetBool(localFlag) {
		config, err = clientcmd.BuildConfigFromFlags("", filepath.Join(homedir.HomeDir(), ".kube", "config"))
		if err != nil {
			log.Fatal(err)
		}
	} else {
		// use the current context in kubeconfig
		config, err = restclient.InClusterConfig()
		if err != nil {
			log.Fatalf("Failed to load kube config. Running in Kubernetes?\n%s", err)
		}
	}

	log.Debugf("Kubernetes master from config: %s", config.Host)

	kubernetesAPI, err := kubernetes.NewAPI(config)
	if err != nil {
		log.Fatal(err)
	}
	dynClient, err := dynamic.NewForConfig(config)
	if err != nil {
		log.Fatal(err)
	}

	log.Debug("Get blacklist namespaces list...")
	blacklistedNamespacesList := viper.GetStringSlice(blacklistNamespacesFlag)
	blacklistedNamespaces, err := kubernetesAPI.Namespaces(blacklistedNamespacesList)
	if err != nil {
		log.Fatal(err)
	}
	log.Debug("Getting blacklist namespaces list done.")
	log.Infof("Namespace blacklist: %v", reflect.ValueOf(blacklistedNamespaces).MapKeys())

	resourcesList, err := ServerPreferredListableResources(kubernetesAPI.Client.Discovery())
	if err != nil {
		log.Fatal(err)
	}
	groupVersionResources, err := discovery.GroupVersionResources(resourcesList)
	if err != nil {
		log.Panic(err)
	}

	log.Debug("Listing nodes...")
	nodes, err := kubernetesAPI.Nodes()
	if err != nil {
		log.Fatal(err)
	}
	log.Debug("Listing nodes done.")

	log.Debug("Map nodes to Kubernetes object")
	clusterKubernetesObject, err := mapper.MapNodes(
		viper.GetString("clustername"),
		nodes,
	)
	if err != nil {
		log.Fatal(err)
	}

	kubernetesObjects := make([]mapper.KubernetesObject, 0)
	kubernetesObjects = append(kubernetesObjects, *clusterKubernetesObject)

	resourceGroupWhitelist := map[string]map[string]interface{}{
		"": map[string]interface{}{
			"serviceaccounts":        struct{}{},
			"services":               struct{}{},
			"nodes":                  struct{}{},
			"pods":                   struct{}{},
			"namespaces":             struct{}{},
			"configmaps":             struct{}{},
			"persistentvolumes":      struct{}{},
			"persistentvolumeclaims": struct{}{},
			"replicationcontrollers": struct{}{},
		},
		"apps": map[string]interface{}{
			"deployments":  struct{}{},
			"statefulsets": struct{}{},
			"daemonsets":   struct{}{},
			"replicasets":  struct{}{},
		},
		"apiextensions.k8s.io": map[string]interface{}{
			"customresourcedefinitions": struct{}{},
		},
		"rbac.authorization.k8s.io": map[string]interface{}{
			"clusterrolebindings": struct{}{},
			"rolebindings":        struct{}{},
			"clusterroles":        struct{}{},
			"roles":               struct{}{},
		},
		"networking.k8s.io": map[string]interface{}{
			"ingresses":       struct{}{},
			"networkpolicies": struct{}{},
		},
		"autoscaling": map[string]interface{}{
			"horizontalpodautoscalers": struct{}{},
		},
		"policy": map[string]interface{}{
			"podsecuritypolicies": struct{}{},
		},
		"storage.k8s.io": map[string]interface{}{
			"storageclasses": struct{}{},
		},
		"batch": map[string]interface{}{
			"cronjobs": struct{}{},
			"jobs":     struct{}{},
		},
	}

	for gvr := range groupVersionResources {
		if _, ok := resourceGroupWhitelist[gvr.Group][gvr.Resource]; !ok {
			log.Debugf("Not scanning resouce %s", strings.Join([]string{gvr.Group, gvr.Version, gvr.Resource}, "/"))
			continue
		}
		instances, err := dynClient.Resource(gvr).List(metav1.ListOptions{})
		if err != nil {
			log.Panic(err)
		}
		for _, i := range instances.Items {
			if _, ok := blacklistedNamespaces[i.GetNamespace()]; ok {
				continue
			}
			nko := mapper.KubernetesObject{
				Type: i.GetKind(),
				ID:   string(i.GetUID()),
				Data: i.Object,
			}
			kubernetesObjects = append(kubernetesObjects, nko)
		}
	}

	customFields := mapper.CustomFields{
		ConnectorInstance: viper.GetString(connectorIDFlag),
		BuildVersion:      version.VERSION,
	}

	ldif := mapper.LDIF{
		ConnectorID:         "Kubernetes",
		ConnectorType:       "leanix-k8s-connector",
		ConnectorVersion:    viper.GetString(connectorVersionFlag),
		ProcessingDirection: "inbound",
		LxVersion:           lxVersion,
		LxWorkspace:         viper.GetString(lxWorkspaceFlag),
		Description:         "Map Kubernetes objects to LeanIX Fact Sheets",
		CustomFields:        customFields,
		Content:             kubernetesObjects,
	}

	log.Debug("Marshal ldif")
	ldifByte, err := storage.Marshal(ldif)
	if err != nil {
		log.Fatal(err)
	}

	log.Infof("Upload %s to %s", storage.LdifFileName, viper.GetString("storage-backend"))
	azureOpts := storage.AzureBlobOpts{
		AccountName: viper.GetString(azureAccountNameFlag),
		AccountKey:  viper.GetString(azureAccountKeyFlag),
		Container:   viper.GetString(azureContainerFlag),
	}
	localFileOpts := storage.LocalFileOpts{
		Path: viper.GetString(localFilePathFlag),
	}
	uploader, err := storage.NewBackend(viper.GetString("storage-backend"), &azureOpts, &localFileOpts)
	if err != nil {
		log.Fatal(err)
	}
	err = uploader.UploadLdif(ldifByte)
	if err != nil {
		log.Fatal(err)
	}
	if viper.GetBool(integrationAPIFlag) == true {
		accessToken, err := leanix.Authenticate(viper.GetString(integrationAPIFqdnFlag), viper.GetString(integrationAPITokenFlag))
		if err != nil {
			log.Fatal(err)
		}
		log.Info("Integration API authentication successful.")
		syncRun, err := leanix.Upload(viper.GetString(integrationAPIFqdnFlag), accessToken, ldifByte)
		if err != nil {
			log.Fatal(err)
		}
		log.Infof("LDIF successfully uploaded to Integration API. id: %s", syncRun.ID)
		runStatus, err := leanix.StartRun(viper.GetString(integrationAPIFqdnFlag), accessToken, syncRun.ID)
		if err != nil {
			log.Fatal(err)
		}
		log.Infof("Integration API run successfully started. status: %d", runStatus)
	}
	log.Debug("-----------End-----------")
	err = uploader.UploadLog(debugLogBuffer.Bytes())
	if err != nil {
		log.Fatal(err)
	}
	log.Info("-----------End-----------")
}

func ServerPreferredListableResources(d discovery.DiscoveryInterface) ([]*metav1.APIResourceList, error) {
	all, err := discovery.ServerPreferredResources(d)
	return discovery.FilteredBy(discovery.ResourcePredicateFunc(func(groupVersion string, r *metav1.APIResource) bool {
		return strings.Contains(r.Verbs.String(), "list")
	}), all), err
}

func parseFlags() error {
	flag.String(clusterNameFlag, "", "unique name of the Kubernetes cluster")
	flag.String(storageBackendFlag, storage.FileStorage, fmt.Sprintf("storage where the %s file is placed (%s, %s)", storage.LdifFileName, storage.FileStorage, storage.AzureBlobStorage))
	flag.String(azureAccountNameFlag, "", "Azure storage account name")
	flag.String(azureAccountKeyFlag, "", "Azure storage account key")
	flag.String(azureContainerFlag, "", "Azure storage account container")
	flag.String(localFilePathFlag, ".", "path to place the ldif file when using local file storage backend")
	flag.Bool(verboseFlag, false, "verbose log output")
	flag.String(connectorIDFlag, "", "unique id of the LeanIX Kubernetes connector")
	flag.String(connectorVersionFlag, "1.0.0", "connector version defaults to 1.0.0 if not specified")
	flag.Bool(integrationAPIFlag, false, "enable Integration API usage")
	flag.String(integrationAPIFqdnFlag, "app.leanix.net", "LeanIX Instance FQDN")
	flag.String(integrationAPITokenFlag, "", "LeanIX API token")
	flag.StringSlice(blacklistNamespacesFlag, []string{""}, "list of namespaces that are not scanned")
	flag.String(lxWorkspaceFlag, "", "name of the LeanIX workspace the data is sent to")
	flag.Bool(localFlag, false, "use local kubeconfig from home folder")
	flag.Parse()
	// Let flags overwrite configs in viper
	err := viper.BindPFlags(flag.CommandLine)
	if err != nil {
		return err
	}
	// Check for config values in env vars
	viper.AutomaticEnv()
	replacer := strings.NewReplacer("-", "_")
	viper.SetEnvKeyReplacer(replacer)
	if viper.GetString(clusterNameFlag) == "" {
		return fmt.Errorf("%s flag must be set", clusterNameFlag)
	}
	if viper.GetString(connectorIDFlag) == "" {
		return fmt.Errorf("%s flag must be set", connectorIDFlag)
	}
	if viper.GetString(lxWorkspaceFlag) == "" {
		return fmt.Errorf("%s flag must be set", lxWorkspaceFlag)
	}
	if viper.GetString(storageBackendFlag) == "azureblob" {
		if viper.GetString(azureAccountNameFlag) == "" {
			return fmt.Errorf("%s flag must be set", azureAccountNameFlag)
		}
		if viper.GetString(azureAccountKeyFlag) == "" {
			return fmt.Errorf("%s flag must be set", azureAccountKeyFlag)
		}
		if viper.GetString(azureContainerFlag) == "" {
			return fmt.Errorf("%s flag must be set", azureContainerFlag)
		}
	}
	if viper.GetBool(integrationAPIFlag) == true {
		if viper.GetString(integrationAPITokenFlag) == "" {
			return fmt.Errorf("%s flag must be set", integrationAPITokenFlag)
		}
	}
	return nil
}

// InitLogger initialise the logger for stdout and log file
func initLogger() (logging.LeveledBackend, *bytes.Buffer) {
	format := logging.MustStringFormatter(`%{time} â–¶ [%{level:.4s}] %{message}`)
	logging.SetFormatter(format)

	// stdout logging backend
	stdout := logging.NewLogBackend(os.Stdout, "", 0)
	stdoutLeveled := logging.AddModuleLevel(stdout)

	// file logging backend
	var mem bytes.Buffer
	fileLogger := logging.NewLogBackend(&mem, "", 0)
	logging.SetBackend(fileLogger, stdoutLeveled)
	return stdoutLeveled, &mem
}

func enableVerbose(logger logging.LeveledBackend, verbose bool) {
	if verbose {
		logger.SetLevel(logging.DEBUG, "")
	} else {
		logger.SetLevel(logging.INFO, "")
	}
}
